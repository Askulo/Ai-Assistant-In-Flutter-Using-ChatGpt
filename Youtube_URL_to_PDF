{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Askulo/Ai-Assistant-In-Flutter-Using-ChatGpt/blob/master/Youtube_URL_to_PDF\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, install the required packages\n",
        "!pip install opencv-python-headless\n",
        "!pip install scikit-image\n",
        "!pip install fpdf\n",
        "!pip install yt-dlp\n",
        "!pip install youtube_transcript_api\n",
        "!apt-get install ffmpeg\n",
        "!pip install requests==2.31.0  # Manually installing the required version of requests\n",
        "\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import tempfile\n",
        "from PIL import Image\n",
        "from fpdf import FPDF\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "import yt_dlp\n",
        "from google.colab import files\n",
        "\n",
        "def download_video(url, output_file):\n",
        "    if os.path.exists(output_file):\n",
        "        os.remove(output_file)\n",
        "    ydl_opts = {\n",
        "        'outtmpl': output_file,\n",
        "        'format': 'best',\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "\n",
        "def get_video_id(url):\n",
        "    patterns = [\n",
        "        r\"shorts\\/(\\w+)\",\n",
        "        r\"youtu\\.be\\/([\\w\\-_]+)(\\?.*)?\",\n",
        "        r\"v=([\\w\\-_]+)\",\n",
        "        r\"live\\/(\\w+)\"\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, url)\n",
        "        if match:\n",
        "            return match.group(1)\n",
        "    return None\n",
        "\n",
        "def get_captions(video_id, lang='en'):\n",
        "    try:\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[lang])\n",
        "        return [(t['start'] * 1000, t['duration'] * 1000, t['text']) for t in transcript]\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching captions: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_unique_frames(video_file, output_folder, n=3, ssim_threshold=0.8):\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    last_frame = None\n",
        "    saved_frame = None\n",
        "    frame_number = 0\n",
        "    timestamps = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_number % n == 0:\n",
        "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            gray_frame = cv2.resize(gray_frame, (128, 72))\n",
        "\n",
        "            if last_frame is not None:\n",
        "                similarity = compare_ssim(gray_frame, last_frame, data_range=gray_frame.max() - gray_frame.min())\n",
        "                if similarity < ssim_threshold:\n",
        "                    if saved_frame is not None and frame_number - len(timestamps) > fps:\n",
        "                        frame_path = os.path.join(output_folder, f'frame{frame_number:04d}.png')\n",
        "                        cv2.imwrite(frame_path, saved_frame)\n",
        "                        timestamps.append(frame_number / fps)\n",
        "                    saved_frame = frame\n",
        "                else:\n",
        "                    saved_frame = frame\n",
        "            else:\n",
        "                frame_path = os.path.join(output_folder, f'frame{frame_number:04d}.png')\n",
        "                cv2.imwrite(frame_path, frame)\n",
        "                timestamps.append(frame_number / fps)\n",
        "\n",
        "            last_frame = gray_frame\n",
        "\n",
        "        frame_number += 1\n",
        "\n",
        "    cap.release()\n",
        "    return timestamps\n",
        "\n",
        "def convert_frames_to_pdf(input_folder, output_file, timestamps):\n",
        "    frame_files = sorted(os.listdir(input_folder), key=lambda x: int(x.split('frame')[1].split('.')[0]))\n",
        "    pdf = FPDF(\"L\")\n",
        "    pdf.set_auto_page_break(0)\n",
        "\n",
        "    for i, frame_file in enumerate(frame_files):\n",
        "        frame_path = os.path.join(input_folder, frame_file)\n",
        "        image = Image.open(frame_path)\n",
        "        pdf.add_page()\n",
        "        pdf.image(frame_path, x=0, y=0, w=pdf.w, h=pdf.h)\n",
        "\n",
        "        timestamp = f\"{int(timestamps[i] // 3600):02d}:{int((timestamps[i] % 3600) // 60):02d}:{int(timestamps[i] % 60):02d}\"\n",
        "\n",
        "        x, y, width, height = 5, 5, 60, 15\n",
        "        region = image.crop((x, y, x + width, y + height)).convert(\"L\")\n",
        "        mean_pixel_value = region.resize((1, 1)).getpixel((0, 0))\n",
        "        pdf.set_text_color(255, 255, 255) if mean_pixel_value < 64 else pdf.set_text_color(0, 0, 0)\n",
        "\n",
        "        pdf.set_xy(x, y)\n",
        "        pdf.set_font(\"Arial\", size=12)\n",
        "        pdf.cell(0, 0, timestamp)\n",
        "\n",
        "    pdf.output(output_file)\n",
        "\n",
        "def create_transcripts_pdf(output_file, timestamps, captions):\n",
        "    pdf = FPDF(\"P\")\n",
        "    pdf.set_auto_page_break(0)\n",
        "    page_height = pdf.h\n",
        "\n",
        "    caption_index = 0\n",
        "    for i, timestamp_seconds in enumerate(timestamps):\n",
        "        pdf.add_page()\n",
        "\n",
        "        timestamp = f\"{int(timestamp_seconds // 3600):02d}:{int((timestamp_seconds % 3600) // 60):02d}:{int(timestamp_seconds % 60):02d}\"\n",
        "        pdf.set_text_color(0, 0, 0)\n",
        "        pdf.set_xy(10, 10)\n",
        "        pdf.set_font(\"Arial\", size=14)\n",
        "        pdf.cell(0, 0, timestamp)\n",
        "\n",
        "        if captions and caption_index < len(captions):\n",
        "            transcript = \"\"\n",
        "            start_time = 0 if i == 0 else timestamps[i - 1]\n",
        "            end_time = timestamp_seconds\n",
        "\n",
        "            while caption_index < len(captions) and start_time * 1000 <= captions[caption_index][0] < end_time * 1000:\n",
        "                transcript += f\"{captions[caption_index][2]}\\n\"\n",
        "                caption_index += 1\n",
        "\n",
        "            pdf.set_text_color(0, 0, 0)\n",
        "            pdf.set_xy(10, 25)\n",
        "            pdf.set_font(\"Arial\", size=10)\n",
        "            lines = transcript.split(\"\\n\")\n",
        "            for line in lines:\n",
        "                if pdf.get_y() + 10 > page_height:\n",
        "                    pdf.add_page()\n",
        "                    pdf.set_xy(10, 10)\n",
        "                pdf.cell(0, 10, line)\n",
        "                pdf.ln()\n",
        "\n",
        "    pdf.output(output_file)\n",
        "\n",
        "def get_video_title(url):\n",
        "    ydl_opts = {\n",
        "        'skip_download': True,\n",
        "        'ignoreerrors': True\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        video_info = ydl.extract_info(url, download=False)\n",
        "        title = video_info['title'].replace('/', '-').replace('\\\\', '-').replace(':', '-').replace('*', '-').replace('?', '-').replace('<', '-').replace('>', '-').replace('|', '-').replace('\"', '-').strip('.')\n",
        "        return title\n",
        "\n",
        "def main(urls):\n",
        "    for video_url in urls:\n",
        "        video_id = get_video_id(video_url)\n",
        "        if not video_id:\n",
        "            print(f\"Invalid URL: {video_url}\")\n",
        "            continue\n",
        "\n",
        "        video_title = get_video_title(video_url)\n",
        "        video_file = f\"video_{video_id}.mp4\"\n",
        "        download_video(video_url, video_file)\n",
        "\n",
        "        captions = get_captions(video_id)\n",
        "\n",
        "        output_pdf_filename = f\"{video_title}.pdf\"\n",
        "        transcript_pdf_filename = f\"txt_{video_title}.pdf\"\n",
        "\n",
        "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "            frames_folder = os.path.join(tmp_dir, \"frames\")\n",
        "            os.makedirs(frames_folder)\n",
        "\n",
        "            timestamps = extract_unique_frames(video_file, frames_folder)\n",
        "            convert_frames_to_pdf(frames_folder, output_pdf_filename, timestamps)\n",
        "            create_transcripts_pdf(transcript_pdf_filename, timestamps, captions)\n",
        "\n",
        "        print(f\"Slides PDF: {output_pdf_filename}\")\n",
        "        print(f\"Transcripts PDF: {transcript_pdf_filename}\")\n",
        "        files.download(output_pdf_filename)\n",
        "        files.download(transcript_pdf_filename)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    urls = [\"https://www.youtube.com/live/ZytRmMCY2_o?si=24pkX4Jxsx1MZxV8\"]\n",
        "    main(urls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HlLG3H0QS3n-",
        "outputId": "27116ab5-ef52-467f-9b1c-418bac47f327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.1)\n",
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2024.7.16)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.7.4)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (3.20.0)\n",
            "Collecting requests<3,>=2.32.2 (from yt-dlp)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Requirement already satisfied: websockets>=12.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.7)\n",
            "Installing collected packages: requests\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed requests-2.32.3\n",
            "Requirement already satisfied: youtube_transcript_api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2024.7.4)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Collecting requests==2.31.0\n",
            "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2024.7.4)\n",
            "Installing collected packages: requests\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yt-dlp 2024.7.16 requires requests<3,>=2.32.2, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed requests-2.31.0\n",
            "[youtube] Extracting URL: https://www.youtube.com/live/ZytRmMCY2_o?si=24pkX4Jxsx1MZxV8\n",
            "[youtube] ZytRmMCY2_o: Downloading webpage\n",
            "[youtube] ZytRmMCY2_o: Downloading ios player API JSON\n",
            "[youtube] ZytRmMCY2_o: Downloading m3u8 information\n",
            "[youtube] Extracting URL: https://www.youtube.com/live/ZytRmMCY2_o?si=24pkX4Jxsx1MZxV8\n",
            "[youtube] ZytRmMCY2_o: Downloading webpage\n",
            "[youtube] ZytRmMCY2_o: Downloading ios player API JSON\n",
            "[youtube] ZytRmMCY2_o: Downloading m3u8 information\n",
            "[info] ZytRmMCY2_o: Downloading 1 format(s): 18\n",
            "[download] Destination: video_ZytRmMCY2_o.mp4\n",
            "[download] 100% of  108.52MiB in 00:00:37 at 2.92MiB/s   \n",
            "Error fetching captions: \n",
            "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=ZytRmMCY2_o! This is most likely caused by:\n",
            "\n",
            "No transcripts were found for any of the requested language codes: ['en']\n",
            "\n",
            "For this video (ZytRmMCY2_o) transcripts are available in the following languages:\n",
            "\n",
            "(MANUALLY CREATED)\n",
            "None\n",
            "\n",
            "(GENERATED)\n",
            " - hi (\"Hindi (auto-generated)\")[TRANSLATABLE]\n",
            "\n",
            "(TRANSLATION LANGUAGES)\n",
            " - af (\"Afrikaans\")\n",
            " - ak (\"Akan\")\n",
            " - sq (\"Albanian\")\n",
            " - am (\"Amharic\")\n",
            " - ar (\"Arabic\")\n",
            " - hy (\"Armenian\")\n",
            " - as (\"Assamese\")\n",
            " - ay (\"Aymara\")\n",
            " - az (\"Azerbaijani\")\n",
            " - bn (\"Bangla\")\n",
            " - eu (\"Basque\")\n",
            " - be (\"Belarusian\")\n",
            " - bho (\"Bhojpuri\")\n",
            " - bs (\"Bosnian\")\n",
            " - bg (\"Bulgarian\")\n",
            " - my (\"Burmese\")\n",
            " - ca (\"Catalan\")\n",
            " - ceb (\"Cebuano\")\n",
            " - zh-Hans (\"Chinese (Simplified)\")\n",
            " - zh-Hant (\"Chinese (Traditional)\")\n",
            " - co (\"Corsican\")\n",
            " - hr (\"Croatian\")\n",
            " - cs (\"Czech\")\n",
            " - da (\"Danish\")\n",
            " - dv (\"Divehi\")\n",
            " - nl (\"Dutch\")\n",
            " - en (\"English\")\n",
            " - eo (\"Esperanto\")\n",
            " - et (\"Estonian\")\n",
            " - ee (\"Ewe\")\n",
            " - fil (\"Filipino\")\n",
            " - fi (\"Finnish\")\n",
            " - fr (\"French\")\n",
            " - gl (\"Galician\")\n",
            " - lg (\"Ganda\")\n",
            " - ka (\"Georgian\")\n",
            " - de (\"German\")\n",
            " - el (\"Greek\")\n",
            " - gn (\"Guarani\")\n",
            " - gu (\"Gujarati\")\n",
            " - ht (\"Haitian Creole\")\n",
            " - ha (\"Hausa\")\n",
            " - haw (\"Hawaiian\")\n",
            " - iw (\"Hebrew\")\n",
            " - hi (\"Hindi\")\n",
            " - hmn (\"Hmong\")\n",
            " - hu (\"Hungarian\")\n",
            " - is (\"Icelandic\")\n",
            " - ig (\"Igbo\")\n",
            " - id (\"Indonesian\")\n",
            " - ga (\"Irish\")\n",
            " - it (\"Italian\")\n",
            " - ja (\"Japanese\")\n",
            " - jv (\"Javanese\")\n",
            " - kn (\"Kannada\")\n",
            " - kk (\"Kazakh\")\n",
            " - km (\"Khmer\")\n",
            " - rw (\"Kinyarwanda\")\n",
            " - ko (\"Korean\")\n",
            " - kri (\"Krio\")\n",
            " - ku (\"Kurdish\")\n",
            " - ky (\"Kyrgyz\")\n",
            " - lo (\"Lao\")\n",
            " - la (\"Latin\")\n",
            " - lv (\"Latvian\")\n",
            " - ln (\"Lingala\")\n",
            " - lt (\"Lithuanian\")\n",
            " - lb (\"Luxembourgish\")\n",
            " - mk (\"Macedonian\")\n",
            " - mg (\"Malagasy\")\n",
            " - ms (\"Malay\")\n",
            " - ml (\"Malayalam\")\n",
            " - mt (\"Maltese\")\n",
            " - mi (\"MƒÅori\")\n",
            " - mr (\"Marathi\")\n",
            " - mn (\"Mongolian\")\n",
            " - ne (\"Nepali\")\n",
            " - nso (\"Northern Sotho\")\n",
            " - no (\"Norwegian\")\n",
            " - ny (\"Nyanja\")\n",
            " - or (\"Odia\")\n",
            " - om (\"Oromo\")\n",
            " - ps (\"Pashto\")\n",
            " - fa (\"Persian\")\n",
            " - pl (\"Polish\")\n",
            " - pt (\"Portuguese\")\n",
            " - pa (\"Punjabi\")\n",
            " - qu (\"Quechua\")\n",
            " - ro (\"Romanian\")\n",
            " - ru (\"Russian\")\n",
            " - sm (\"Samoan\")\n",
            " - sa (\"Sanskrit\")\n",
            " - gd (\"Scottish Gaelic\")\n",
            " - sr (\"Serbian\")\n",
            " - sn (\"Shona\")\n",
            " - sd (\"Sindhi\")\n",
            " - si (\"Sinhala\")\n",
            " - sk (\"Slovak\")\n",
            " - sl (\"Slovenian\")\n",
            " - so (\"Somali\")\n",
            " - st (\"Southern Sotho\")\n",
            " - es (\"Spanish\")\n",
            " - su (\"Sundanese\")\n",
            " - sw (\"Swahili\")\n",
            " - sv (\"Swedish\")\n",
            " - tg (\"Tajik\")\n",
            " - ta (\"Tamil\")\n",
            " - tt (\"Tatar\")\n",
            " - te (\"Telugu\")\n",
            " - th (\"Thai\")\n",
            " - ti (\"Tigrinya\")\n",
            " - ts (\"Tsonga\")\n",
            " - tr (\"Turkish\")\n",
            " - tk (\"Turkmen\")\n",
            " - uk (\"Ukrainian\")\n",
            " - ur (\"Urdu\")\n",
            " - ug (\"Uyghur\")\n",
            " - uz (\"Uzbek\")\n",
            " - vi (\"Vietnamese\")\n",
            " - cy (\"Welsh\")\n",
            " - fy (\"Western Frisian\")\n",
            " - xh (\"Xhosa\")\n",
            " - yi (\"Yiddish\")\n",
            " - yo (\"Yoruba\")\n",
            " - zu (\"Zulu\")\n",
            "\n",
            "If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\n",
            "Slides PDF: Decomposition - L 13 -  DBMS - Infinity Batch - GATE 2022 - Ankush Sir.pdf\n",
            "Transcripts PDF: txt_Decomposition - L 13 -  DBMS - Infinity Batch - GATE 2022 - Ankush Sir.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ff7adc4-f656-4c80-874a-68639bcd2fbe\", \"Decomposition - L 13 -  DBMS - Infinity Batch - GATE 2022 - Ankush Sir.pdf\", 6423873)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0809d032-08a6-4914-a163-6f6b910258ba\", \"txt_Decomposition - L 13 -  DBMS - Infinity Batch - GATE 2022 - Ankush Sir.pdf\", 11285)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTZC1KD2RgtcsIBaUYLOlp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}